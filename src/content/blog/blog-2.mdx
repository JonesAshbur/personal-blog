---
title: '什么是AI幻觉？什么是RAG？'
description: 'LLM，AI hallucination，RAG'
date: '2025-04-03'
---
在AI文本生成的过程中，AI 幻觉（Artificial intelligent hallucination）极大的影响了问题答案的真实性和可靠性。那么什么是AI幻觉，即模型在缺乏真实，可靠的数据的情况下AI自主编造信息，导致生成不准确的，并且具有误导性的内容。AI幻觉不仅影响 AI 在专业领域的应用可靠性，也限制了其作为知识工具的可信度。为了解决这一问题，RAG（检索增强生成）技术诞生。RAG 通过结合外部知识库，使 AI 在回答问题时能够参考真实数据，从而减少幻觉的发生，提高了生成内容的准确性和真实性。接下来文章将探讨造成AI 幻觉的主要因素，并分析 RAG 如何降低AI幻觉。

## 一、LLM 文本生成工作原理

在了解为什么会出现AI幻觉之前，我们需要先知道AI如何给我们生成答案，即LLM（Large language model）文本生成的工作原理。


### 1.基于概率的文本生成

LLM并不会真正“理解”语言，而是基于大量文本数据进行训练，学习单词、短语和句子之间的相互关系。模型生成文本时，实际上是在预测下一个最有可能出现的词，预测过程基于条件概率计算。例如，在输入“你是什么模型”后，模型会计算“模型”，“语言模型”，“视频模型”等多个邻近词，并不是依赖事实进行查询。

### 2.使用Softmax计算概率分布

在实际计算过程中，模型会基于神经网络（主流 Transformer 架构）计算每个单词的分数（logits），然后通过 Softmax 函数将其转换为一个概率分布。


最终，模型根据概率分布进行采样，选择概率最大的一个词并且继续生成下一个。

### 3.一个重要参数-Temperature

文本生成时，温度参数（Temperature）可以控制输出的确定性亦或是随机性：

1. **低温度（如 0.5）** 可能会选择最高概率的词，生成结果更稳定，但是内容可能不够丰富。
2. **高温度（如 1.5）** 可能会选取较低概率的词，增加文本生成内容多样性，但也可能导致幻觉的出现。
![](/images/2025-04-03-234412.png)

## 二、RAG 检索增强生成的工作原理

在了解了LLM文本生成工作原理后，我们知道了为什么会出现AI幻觉，如何减少AI幻觉的出现呢? RAG（Retrieval-Augmented Generation）给我们提供了一种减少AI幻觉的方案。

RAG是一种AI框架，通过将大语言模型与外部数据源相关联，来提升文本输出质量。

### 1.总体工作图示：

![](/images/2025-04-03-203152.png)

在此过程中，系统先将用户提出的问题转换为向量表示，然后在向量数据库中（外部数据源，即LLM未曾训练过的数据）进行相似性搜索，当然向量数据库中的数据并非日常所见的数据，而是转换后的向量数据。系统将与问题相关的信息检索完毕后，将问题与检索结果一同输入到提示词模板中，从而诞生新的提示词，然后将新诞生的提示词发送给LLM，经过LLM的处理，生成最终答案，返回给用户。

### 2.RAG的优点

1. 降低AI幻觉
2. 及时提供最新的数据，避免LLM的知识缺乏
3. 降低LLM微调成本

### 3.RAG工作流程

![](/images/2025-04-03-215643.png)

​在外部数据源中充斥着各类数据文件，首先将这些文件进行分割成token（分割的质量直接影响了信息检索准确性和文本生成的最终效果），然后通过嵌入模型提取相关特征形成特征向量，放入向量数据库中（区别于传统数据库中结构化数据的精确匹配，向量数据库中的非结构化数据更加侧重于相似性搜索，包容性更好）。在获取用户输入的问题后通过相似的步骤进行处理，再经过检索之后，找到与用户问题相似度最高的K个数据，然后进一步排序，最终确定N个有序的最优结果。将最优结果（context），提示词，用户问题交给LLM，通过LLM分析后，将最终结果返回用户。

​经过上述一系列步骤，从而有效降低AI幻觉。

