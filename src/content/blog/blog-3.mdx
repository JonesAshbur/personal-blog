---
title: '有关AI的部分概念'
description: 'AI'
date: '2025-04-07'
---


**AI**  （Artificial Intelligence）即人工智能。人工智能是一个广泛的科学领域，涉及计算机科 学、心理学、哲学和语言学等多个学科。它主要研究、开发用于模拟、延伸和扩展人的智能的理论、方法、技术及应用系统，是计算机科学的一个重要分支。 

**AIGC**  （Artificial Intelligence Generated Content）即人工智能生成内容。它指的是利用人工智能技术来生成原本由人类进行创作的文本、图像、音频、视频、游戏、代码等内容。 AIGC的技术基础是生成式人工智能（Generative AI），这是一种通过机器学习从数据中学习并生成全新内容的技术。能够创建出全新的、完全原创的内容，如图像、文本或音频。

**AGI** （Artificial General Intelligence）即通用人工智能。AGI 指的是具有广泛且通用能力的人工智能系统，这种智能可以应用于各种不同的任务和领域，并且能够像人类一样学习和适应新环境。 

**NLP**  （Natural Language Processing）即自然语言处理。它是一门融合语言学、计算机科学、数学于一体的交叉学科，主要研究能实现人与计算机之间用自然语言进行有效通信的各种理论和方法。自然语言处理是人工智能领域的一个重要方向，它涉及对文本、语音等自然语言信息的处理和理解，包括语言识别、语言生成、语言理解和语言翻译等方面。

**LLM**  （Large Language Model）即大语言模型，是基于深度神经网络的自然语言处理模型，通过预训练和模型微调的方式，在大规模文本数据上进行训练，从而生成、理解和处理自然语言文本。 

**GPT**  （Generative Pre-trained Transformer）即生成式预训练 Transformer，它是一种基于Transformer架构的预训练大语言模型，用于生成和理解自然语言文本。GPT通过在大规模文本数据上进行无监督的预训练，学习语言的规律和知识，并能够在多种自然语言处理任务中展现出卓越的性能，如文本生成、问答系统、语言翻译等。

**CUI**（Command User Interface） 即命令行用户接口 （只有命令行交互界面，对计算机的一切控制通过指令实现）

**GUI**（Graphical User Interface） 即图形用户接口（具有图形界面，用户使用更加便捷）

**LUI**（Language User Interface） 即语言用户接口（通过语音识别，执行用户指令）

**Token**：模型用来表示自然语言文本的基本单位，通常是大模型的计费单元，可以直观的理解为“字”或“词”；通常 1 个中文词语、1 个英文单词、1 个数字或 1 个符号计为 1 个 token。

一般情况下模型中 token 和字数的换算比例大致如下：

- 1 个英文字符 ≈ 0.3 个 token。
- 1 个中文字符 ≈ 0.6 个 token。

但因为不同模型的分词器不同，所以换算比例也存在差异。

## 什么是Prompt

通俗解释：  Prompt是一种指令或信息，它引导或触发AI做出回应。在与AI大模型的交互中，每当我们输入一段文字，无论是问题、命令还是陈述，这段文字就是Prompt。

### LLM如何处理Prompt

**1. Prompt输入:** Prompt是你提供给LLM的初始文本输入。它可以是一个问题、一个陈述、一个请求，甚至只是一些关键词。你可以把它想象成一套指导模型执行特定任务的指令。

**2. 分词处理 (Tokenization):** 当你输入一个提示时，LLM首先会将其分解成更小的单元，称为“tokens”。这些令牌可以是单个的词语、词语的一部分，甚至是标点符号。这种分词处理使得模型能够以数字化的方式处理文本。

**3. 编码与理解 (Encoding and Understanding):** 每一个令牌都会被转换成一个称为“嵌入（embedding）”的数值表示。这些嵌入是高维向量，能够捕捉词语之间的语义含义和关系。LLM利用其庞大的训练数据来理解你的提示背后的上下文和意图。它通过分析这些嵌入，识别你使用的词语和短语之间的模式和联系。

**4. 生成回应 (Generating a Response):** 基于对提示的理解，LLM会预测接下来最有可能出现的token序列。它逐个token地进行预测，同时考虑整个提示的上下文及其内部知识。这个预测过程是概率性的。模型并非只是选择唯一“正确”的下一个词，而是会考虑一系列可能性，并选择概率最高的那个，通常还会加入一些随机性以使输出更自然和富有创造性。然后重新转换为自然语言返回。

## LLM Prompt Engineering相关概念

1. **零样本提示 (Zero-shot prompting):** 在不提供任何示例的情况下，要求模型执行任务（返回结果随机性最大）。
2. **少样本提示 (Few-shot prompting):** 提供少量示例来指导模型的回应。
3. **思维链提示 (Chain-of-thought prompting):** 引导模型展示其推理步骤，以便为复杂的任务得出更准确的答案。
4. **提示引导 (Prompt priming):** 提供初始的指令或上下文，以引导模型的行为朝着特定方向发展。



## 设计提示词

一个好的Prompt可以极大地提高我们的工作效率和模型生成效果。中文的丰富性和多样性赋予了Prompt极高的灵活性和变化性。这样的话就会导致Prompt没有固定的格式，所以掌握一些编写Prompt技巧可以帮助我们更有效地使用LLM，从而达到事半功倍的效果。以下是一些编写 Prompt的技巧： 

1. **清晰的任务目标**：首先明确任务目标，这有助于LLM更好的理解你的需求。
2. **Context**：提供基于任务的上下文信息，即和任务相关的资料（各种类型：图片，文字，代码等等）。
3. **设定限制**：给LLM设定限制，以防止生成一些冗余的信息。
4. **对话引导**：在对话过程中提供一定的引导性提示词，进一步与LLM进行沟通。
5. **迭代**：根据每次LLM返回的结果，判断是否符合自己的预期，如果与预期偏差较大或者想进一步完善结果，则针对当下问题给出进一步提示或限制。
6. **思维链**：将问题分解成更小的子问题，然后一步步解决，直到满足要求。



